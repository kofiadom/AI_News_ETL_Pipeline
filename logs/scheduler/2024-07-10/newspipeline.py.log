[2024-07-10T06:48:58.340+0000] {processor.py:161} INFO - Started process (PID=37) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T06:48:58.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T06:48:59.956+0000] {logging_mixin.py:188} INFO - [2024-07-10T06:48:58.347+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T06:49:31.421+0000] {logging_mixin.py:188} INFO - [2024-07-10T06:49:31.044+0000] {timeout.py:68} ERROR - Process timed out, PID: 37
[2024-07-10T06:50:08.750+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T06:50:08.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T06:50:09.462+0000] {logging_mixin.py:188} INFO - [2024-07-10T06:50:09.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T06:50:39.562+0000] {logging_mixin.py:188} INFO - [2024-07-10T06:50:39.560+0000] {timeout.py:68} ERROR - Process timed out, PID: 51
[2024-07-10T06:51:18.361+0000] {processor.py:161} INFO - Started process (PID=65) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T06:51:18.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T06:51:18.783+0000] {logging_mixin.py:188} INFO - [2024-07-10T06:51:18.706+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T06:52:31.900+0000] {processor.py:161} INFO - Started process (PID=85) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T06:52:31.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T06:52:31.909+0000] {logging_mixin.py:188} INFO - [2024-07-10T06:52:31.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T06:54:31.166+0000] {processor.py:161} INFO - Started process (PID=99) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T06:54:31.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T06:54:40.333+0000] {logging_mixin.py:188} INFO - [2024-07-10T06:54:31.997+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T06:57:21.668+0000] {logging_mixin.py:188} INFO - [2024-07-10T06:56:29.864+0000] {timeout.py:68} ERROR - Process timed out, PID: 99
[2024-07-10T06:59:52.348+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T06:59:52.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T06:59:52.354+0000] {logging_mixin.py:188} INFO - [2024-07-10T06:59:52.353+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:00:22.674+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:00:22.674+0000] {timeout.py:68} ERROR - Process timed out, PID: 107
[2024-07-10T07:00:53.088+0000] {processor.py:161} INFO - Started process (PID=122) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:00:53.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:00:53.091+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:00:53.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:01:23.095+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:01:23.095+0000] {timeout.py:68} ERROR - Process timed out, PID: 122
[2024-07-10T07:01:54.150+0000] {processor.py:161} INFO - Started process (PID=135) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:01:54.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:01:54.153+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:01:54.152+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:02:29.197+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:02:24.368+0000] {timeout.py:68} ERROR - Process timed out, PID: 135
[2024-07-10T07:06:04.427+0000] {processor.py:161} INFO - Started process (PID=143) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:06:04.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:06:04.430+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:06:04.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:06:18.694+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T07:06:18.733+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:06:18.728+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T07:06:18.734+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:06:18.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 14.684 seconds
[2024-07-10T07:06:49.161+0000] {processor.py:161} INFO - Started process (PID=158) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:06:49.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:06:49.164+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:06:49.164+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:07:03.852+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T07:07:03.857+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:07:03.853+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T07:07:03.962+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:07:03.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 14.820 seconds
[2024-07-10T07:07:34.214+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:07:34.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:07:34.216+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:07:34.216+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:08:04.226+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:08:04.223+0000] {timeout.py:68} ERROR - Process timed out, PID: 166
[2024-07-10T07:08:34.408+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:08:34.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:08:34.413+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:08:34.412+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:08:48.961+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T07:08:48.979+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:08:48.971+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T07:08:48.980+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:08:48.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 14.598 seconds
[2024-07-10T07:09:19.229+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:09:19.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:09:19.232+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:09:19.231+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:09:50.474+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:09:49.628+0000] {timeout.py:68} ERROR - Process timed out, PID: 194
[2024-07-10T07:10:43.893+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:10:43.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:10:43.900+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:10:43.900+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:11:15.949+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:11:15.505+0000] {timeout.py:68} ERROR - Process timed out, PID: 196
[2024-07-10T07:11:57.272+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:11:57.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:11:57.276+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:11:57.275+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:12:18.886+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T07:12:18.912+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:12:18.897+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T07:12:18.913+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:12:18.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 21.664 seconds
[2024-07-10T07:12:49.059+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:12:49.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:12:49.061+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:12:49.061+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:13:11.143+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T07:13:11.155+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:13:11.145+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T07:13:11.156+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:13:11.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 22.139 seconds
[2024-07-10T07:13:41.429+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:13:41.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:13:41.436+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:13:41.434+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:16:01.246+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:16:01.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:16:01.393+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:16:01.370+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:17:00.693+0000] {processor.py:161} INFO - Started process (PID=234) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T07:17:00.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T07:17:00.696+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:17:00.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T07:17:31.908+0000] {logging_mixin.py:188} INFO - [2024-07-10T07:17:30.598+0000] {timeout.py:68} ERROR - Process timed out, PID: 234
[2024-07-10T08:41:28.530+0000] {processor.py:161} INFO - Started process (PID=33) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:41:28.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:41:28.540+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:41:28.540+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:42:04.854+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:42:04.819+0000] {timeout.py:68} ERROR - Process timed out, PID: 33
[2024-07-10T08:42:35.143+0000] {processor.py:161} INFO - Started process (PID=47) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:42:35.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:42:35.165+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:42:35.158+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:43:07.505+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:43:07.439+0000] {timeout.py:68} ERROR - Process timed out, PID: 47
[2024-07-10T08:43:38.843+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:43:38.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:43:39.062+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:43:38.939+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:44:19.954+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:44:19.588+0000] {timeout.py:68} ERROR - Process timed out, PID: 54
[2024-07-10T08:45:06.842+0000] {processor.py:161} INFO - Started process (PID=56) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:45:07.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:45:07.302+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:45:07.104+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:45:38.351+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:45:38.338+0000] {timeout.py:68} ERROR - Process timed out, PID: 56
[2024-07-10T08:46:11.835+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:46:12.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:46:12.871+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:46:12.269+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:46:44.203+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:46:43.915+0000] {timeout.py:68} ERROR - Process timed out, PID: 64
[2024-07-10T08:49:45.858+0000] {processor.py:161} INFO - Started process (PID=65) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:49:48.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:49:48.807+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:49:48.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:52:23.680+0000] {processor.py:161} INFO - Started process (PID=66) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:52:31.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:52:44.736+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:52:44.473+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:55:15.040+0000] {processor.py:161} INFO - Started process (PID=27) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:55:15.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:55:15.072+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:55:15.071+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:55:45.079+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:55:45.077+0000] {timeout.py:68} ERROR - Process timed out, PID: 27
[2024-07-10T08:56:15.304+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:56:15.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:56:15.320+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:56:15.317+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:56:36.583+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T08:56:36.589+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:56:36.585+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T08:56:36.606+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:56:36.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 21.334 seconds
[2024-07-10T08:57:06.758+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:57:06.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:57:06.762+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:57:06.762+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:57:36.779+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:57:36.772+0000] {timeout.py:68} ERROR - Process timed out, PID: 48
[2024-07-10T08:58:06.980+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:58:06.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:58:06.995+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:58:06.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:58:30.692+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T08:58:30.737+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:58:30.705+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T08:58:30.738+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:58:30.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 23.916 seconds
[2024-07-10T08:59:00.927+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:59:00.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:59:00.930+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:59:00.930+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:59:20.114+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T08:59:20.129+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:59:20.117+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T08:59:20.130+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T08:59:20.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 19.218 seconds
[2024-07-10T08:59:50.191+0000] {processor.py:161} INFO - Started process (PID=89) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T08:59:50.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T08:59:50.194+0000] {logging_mixin.py:188} INFO - [2024-07-10T08:59:50.194+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:00:06.363+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:00:06.379+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:00:06.366+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:00:06.380+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:00:06.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 16.217 seconds
[2024-07-10T09:00:36.486+0000] {processor.py:161} INFO - Started process (PID=98) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:00:36.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:00:36.489+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:00:36.489+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:01:00.967+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:01:00.993+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:01:00.979+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:01:00.994+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:01:01.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 24.530 seconds
[2024-07-10T09:01:31.162+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:01:31.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:01:31.165+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:01:31.165+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:01:48.557+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:01:48.576+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:01:48.565+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:01:48.577+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:01:48.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 17.436 seconds
[2024-07-10T09:02:18.738+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:02:18.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:02:18.740+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:02:18.740+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:02:48.756+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:02:48.754+0000] {timeout.py:68} ERROR - Process timed out, PID: 126
[2024-07-10T09:03:18.906+0000] {processor.py:161} INFO - Started process (PID=140) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:03:18.907+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:03:18.909+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:03:18.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:03:49.484+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:03:49.473+0000] {timeout.py:68} ERROR - Process timed out, PID: 140
[2024-07-10T09:04:19.801+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:04:19.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:04:19.804+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:04:19.804+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:04:36.109+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:04:36.132+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:04:36.124+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:04:36.133+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:04:36.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 16.369 seconds
[2024-07-10T09:05:06.249+0000] {processor.py:161} INFO - Started process (PID=162) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:05:06.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:05:06.272+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:05:06.271+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:05:20.943+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:05:20.969+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:05:20.956+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:05:20.970+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:05:20.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 14.763 seconds
[2024-07-10T09:05:51.110+0000] {processor.py:161} INFO - Started process (PID=177) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:05:51.111+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:05:51.113+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:05:51.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:06:21.146+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:06:21.128+0000] {timeout.py:68} ERROR - Process timed out, PID: 177
[2024-07-10T09:06:51.753+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:06:51.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:06:51.756+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:06:51.755+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:07:12.241+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:07:12.273+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:07:12.268+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:07:12.275+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:07:12.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 20.345 seconds
[2024-07-10T09:07:43.114+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:07:43.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:07:43.117+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:07:43.116+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:07:56.881+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:07:56.897+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:07:56.884+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:07:56.898+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:07:56.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 13.831 seconds
[2024-07-10T09:08:27.077+0000] {processor.py:161} INFO - Started process (PID=211) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:08:27.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:08:27.079+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:08:27.079+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:08:42.407+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:08:42.437+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:08:42.431+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:08:42.438+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:08:42.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 15.409 seconds
[2024-07-10T09:09:12.629+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:09:12.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:09:12.632+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:09:12.632+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:09:42.845+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:09:42.869+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:09:42.859+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:09:42.870+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:09:42.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 28.908 seconds
[2024-07-10T09:10:13.293+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:10:13.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:10:13.296+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:10:13.296+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:10:28.341+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:10:28.358+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:10:28.346+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:10:28.359+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:10:28.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 15.102 seconds
[2024-07-10T09:10:59.409+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:10:59.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:10:59.412+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:10:59.412+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:11:29.396+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:11:29.395+0000] {timeout.py:68} ERROR - Process timed out, PID: 240
[2024-07-10T09:11:59.538+0000] {processor.py:161} INFO - Started process (PID=253) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:11:59.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:11:59.541+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:11:59.541+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:12:19.793+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:12:19.824+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:12:19.811+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:12:19.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:12:19.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 20.315 seconds
[2024-07-10T09:12:49.983+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:12:49.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:12:49.986+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:12:49.985+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:13:20.046+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:13:20.005+0000] {timeout.py:68} ERROR - Process timed out, PID: 267
[2024-07-10T09:15:21.476+0000] {processor.py:161} INFO - Started process (PID=26) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:15:21.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:15:21.498+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:15:21.497+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:15:51.294+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:15:51.350+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:15:51.323+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:15:51.351+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:15:51.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 29.912 seconds
[2024-07-10T09:16:22.383+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:16:22.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:16:22.394+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:16:22.391+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:16:52.560+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:16:52.429+0000] {timeout.py:68} ERROR - Process timed out, PID: 41
[2024-07-10T09:17:25.346+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:17:25.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:17:25.356+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:17:25.353+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:17:55.498+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:17:55.404+0000] {timeout.py:68} ERROR - Process timed out, PID: 55
[2024-07-10T09:18:43.678+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:18:43.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:18:43.681+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:18:43.680+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:19:15.106+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:19:13.710+0000] {timeout.py:68} ERROR - Process timed out, PID: 63
[2024-07-10T09:19:45.728+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:19:45.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:19:45.733+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:19:45.731+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:20:15.840+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:20:15.772+0000] {timeout.py:68} ERROR - Process timed out, PID: 76
[2024-07-10T09:20:50.617+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:20:50.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:20:50.621+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:20:50.619+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:21:21.487+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:21:20.757+0000] {timeout.py:68} ERROR - Process timed out, PID: 90
[2024-07-10T09:21:52.817+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:21:52.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:21:52.820+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:21:52.819+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:22:51.342+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:22:26.138+0000] {timeout.py:68} ERROR - Process timed out, PID: 104
[2024-07-10T09:23:21.664+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:23:21.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:23:21.670+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:23:21.668+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:24:00.158+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:23:53.304+0000] {timeout.py:68} ERROR - Process timed out, PID: 118
[2024-07-10T09:24:47.652+0000] {processor.py:161} INFO - Started process (PID=131) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:24:47.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:24:47.654+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:24:47.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:25:19.731+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:25:19.656+0000] {timeout.py:68} ERROR - Process timed out, PID: 131
[2024-07-10T09:25:55.369+0000] {processor.py:161} INFO - Started process (PID=133) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:25:55.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:25:55.371+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:25:55.371+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:26:27.937+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:26:25.733+0000] {timeout.py:68} ERROR - Process timed out, PID: 133
[2024-07-10T09:27:02.772+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:27:02.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:27:02.779+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:27:02.777+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:27:32.235+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:27:32.054+0000] {timeout.py:68} ERROR - Process timed out, PID: 146
[2024-07-10T09:30:38.682+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:30:38.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:30:38.686+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:30:38.685+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:31:09.895+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:31:08.741+0000] {timeout.py:68} ERROR - Process timed out, PID: 160
[2024-07-10T09:31:53.732+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:31:53.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:31:53.734+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:31:53.734+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:32:48.574+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:32:25.909+0000] {timeout.py:68} ERROR - Process timed out, PID: 174
[2024-07-10T09:33:21.992+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:33:21.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:33:21.995+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:33:21.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:33:38.932+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:33:38.970+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:33:38.961+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:33:38.971+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:33:39.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 17.030 seconds
[2024-07-10T09:34:09.188+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:34:09.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:34:09.190+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:34:09.190+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:34:25.871+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:34:25.896+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:34:25.890+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:34:25.897+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:34:25.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 16.731 seconds
[2024-07-10T09:34:56.086+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:34:56.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:34:56.088+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:34:56.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:35:23.283+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:35:23.313+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:35:23.286+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:35:23.314+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:35:23.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 27.248 seconds
[2024-07-10T09:35:53.521+0000] {processor.py:161} INFO - Started process (PID=231) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:35:53.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:35:53.524+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:35:53.524+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:36:10.391+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:36:10.438+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:36:10.433+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:36:10.439+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:36:10.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 16.947 seconds
[2024-07-10T09:36:40.680+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:36:40.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:36:40.683+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:36:40.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:37:11.079+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:37:10.834+0000] {timeout.py:68} ERROR - Process timed out, PID: 239
[2024-07-10T09:37:43.885+0000] {processor.py:161} INFO - Started process (PID=253) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:37:43.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:37:43.888+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:37:43.887+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:38:13.895+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:38:13.894+0000] {timeout.py:68} ERROR - Process timed out, PID: 253
[2024-07-10T09:38:44.058+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:38:44.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:38:44.067+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:38:44.066+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:39:02.431+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:39:02.461+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:39:02.448+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:39:02.462+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:39:02.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 18.439 seconds
[2024-07-10T09:39:32.652+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:39:32.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:39:32.655+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:39:32.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:39:52.052+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:39:52.084+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:39:52.079+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:39:52.085+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:39:52.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 19.499 seconds
[2024-07-10T09:40:22.292+0000] {processor.py:161} INFO - Started process (PID=290) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:40:22.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:40:22.295+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:40:22.294+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:40:52.591+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:40:52.371+0000] {timeout.py:68} ERROR - Process timed out, PID: 290
[2024-07-10T09:41:22.911+0000] {processor.py:161} INFO - Started process (PID=298) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:41:22.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:41:22.914+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:41:22.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:41:55.563+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:41:53.530+0000] {timeout.py:68} ERROR - Process timed out, PID: 298
[2024-07-10T09:42:31.726+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:42:31.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:42:31.729+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:42:31.728+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:43:01.772+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:43:01.738+0000] {timeout.py:68} ERROR - Process timed out, PID: 312
[2024-07-10T09:43:33.410+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:43:33.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:43:33.413+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:43:33.413+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:44:07.296+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:44:04.054+0000] {timeout.py:68} ERROR - Process timed out, PID: 326
[2024-07-10T09:45:00.494+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:45:00.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:45:00.496+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:45:00.496+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:45:30.506+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:45:30.504+0000] {timeout.py:68} ERROR - Process timed out, PID: 340
[2024-07-10T09:46:00.683+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:46:00.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:46:00.686+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:46:00.686+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:46:28.114+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:46:28.142+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:46:28.137+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:46:28.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:46:28.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 27.481 seconds
[2024-07-10T09:46:58.284+0000] {processor.py:161} INFO - Started process (PID=367) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:46:58.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:46:58.287+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:46:58.286+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:47:30.344+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:47:30.318+0000] {timeout.py:68} ERROR - Process timed out, PID: 367
[2024-07-10T09:48:06.223+0000] {processor.py:161} INFO - Started process (PID=381) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:48:06.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:48:06.226+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:48:06.226+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:48:37.177+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:48:36.400+0000] {timeout.py:68} ERROR - Process timed out, PID: 381
[2024-07-10T09:49:15.431+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:49:15.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:49:15.433+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:49:15.433+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:49:46.331+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:49:45.966+0000] {timeout.py:68} ERROR - Process timed out, PID: 395
[2024-07-10T09:50:21.193+0000] {processor.py:161} INFO - Started process (PID=408) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:50:21.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:50:21.197+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:50:21.196+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:50:51.478+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:50:51.476+0000] {timeout.py:68} ERROR - Process timed out, PID: 408
[2024-07-10T09:51:21.696+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:51:21.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:51:21.699+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:51:21.698+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:51:39.991+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T09:51:40.023+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:51:40.013+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-07-10T09:51:40.024+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:51:40.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 18.367 seconds
[2024-07-10T09:52:10.179+0000] {processor.py:161} INFO - Started process (PID=436) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:52:10.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:52:10.182+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:52:10.181+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:52:40.433+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:52:40.318+0000] {timeout.py:68} ERROR - Process timed out, PID: 436
[2024-07-10T09:53:08.684+0000] {processor.py:161} INFO - Started process (PID=449) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:53:08.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:53:08.686+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:53:08.686+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:53:39.444+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:53:38.797+0000] {timeout.py:68} ERROR - Process timed out, PID: 449
[2024-07-10T09:54:12.353+0000] {processor.py:161} INFO - Started process (PID=456) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:54:12.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:54:12.356+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:54:12.356+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:54:43.355+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:54:42.715+0000] {timeout.py:68} ERROR - Process timed out, PID: 456
[2024-07-10T09:55:18.824+0000] {processor.py:161} INFO - Started process (PID=470) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:55:18.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:55:18.827+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:55:18.827+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:55:49.117+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:55:48.974+0000] {timeout.py:68} ERROR - Process timed out, PID: 470
[2024-07-10T09:56:35.256+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:56:35.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:56:35.259+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:56:35.258+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:57:06.963+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:57:05.325+0000] {timeout.py:68} ERROR - Process timed out, PID: 483
[2024-07-10T09:57:39.079+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:57:39.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:57:39.083+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:57:39.081+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:58:10.205+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:58:09.437+0000] {timeout.py:68} ERROR - Process timed out, PID: 498
[2024-07-10T09:58:47.426+0000] {processor.py:161} INFO - Started process (PID=512) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:58:47.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:58:47.429+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:58:47.428+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T09:59:19.086+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:59:17.749+0000] {timeout.py:68} ERROR - Process timed out, PID: 512
[2024-07-10T09:59:52.320+0000] {processor.py:161} INFO - Started process (PID=525) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T09:59:52.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T09:59:52.323+0000] {logging_mixin.py:188} INFO - [2024-07-10T09:59:52.322+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:00:24.961+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:00:22.340+0000] {timeout.py:68} ERROR - Process timed out, PID: 525
[2024-07-10T10:02:04.224+0000] {processor.py:161} INFO - Started process (PID=539) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:02:04.225+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:02:04.227+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:02:04.226+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:02:19.577+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:02:20.453+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:02:20.481+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:02:20.728+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:02:20.727+0000] {override.py:1829} INFO - Created Permission View: can edit on DAG:etl_data_pipeline
[2024-07-10T10:02:20.736+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:02:20.735+0000] {override.py:1829} INFO - Created Permission View: can read on DAG:etl_data_pipeline
[2024-07-10T10:02:20.743+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:02:20.742+0000] {override.py:1829} INFO - Created Permission View: can delete on DAG:etl_data_pipeline
[2024-07-10T10:02:20.743+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:02:20.743+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:02:20.752+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:02:20.752+0000] {dag.py:3118} INFO - Creating ORM DAG for etl_data_pipeline
[2024-07-10T10:02:20.761+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:02:20.761+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:02:20.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 16.540 seconds
[2024-07-10T10:02:50.924+0000] {processor.py:161} INFO - Started process (PID=553) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:02:50.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:02:50.927+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:02:50.926+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:03:06.033+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:03:06.574+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:03:06.583+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:03:06.611+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:03:06.610+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:03:06.629+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:03:06.629+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:03:06.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 15.725 seconds
[2024-07-10T10:03:36.736+0000] {processor.py:161} INFO - Started process (PID=567) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:03:36.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:03:36.739+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:03:36.739+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:04:16.990+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:04:16.412+0000] {timeout.py:68} ERROR - Process timed out, PID: 567
[2024-07-10T10:04:47.529+0000] {processor.py:161} INFO - Started process (PID=575) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:04:47.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:04:47.532+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:04:47.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:05:17.685+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:05:17.579+0000] {timeout.py:68} ERROR - Process timed out, PID: 575
[2024-07-10T10:05:50.099+0000] {processor.py:161} INFO - Started process (PID=589) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:05:50.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:05:50.101+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:05:50.100+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:06:25.469+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:06:20.472+0000] {timeout.py:68} ERROR - Process timed out, PID: 589
[2024-07-10T10:06:57.013+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:06:57.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:06:57.016+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:06:57.014+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:07:26.712+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:07:26.710+0000] {timeout.py:68} ERROR - Process timed out, PID: 603
[2024-07-10T10:07:57.126+0000] {processor.py:161} INFO - Started process (PID=616) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:07:57.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:07:57.128+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:07:57.128+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:08:22.383+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:08:22.889+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:08:22.901+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:08:23.093+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:08:23.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:08:23.110+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:08:23.109+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:08:23.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 26.004 seconds
[2024-07-10T10:08:53.577+0000] {processor.py:161} INFO - Started process (PID=630) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:08:53.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:08:53.886+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:08:53.885+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:09:15.491+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:09:15.966+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:09:15.976+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:09:16.005+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:09:16.004+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:09:16.026+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:09:16.026+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:09:16.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 22.490 seconds
[2024-07-10T10:09:46.184+0000] {processor.py:161} INFO - Started process (PID=644) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:09:46.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:09:46.186+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:09:46.186+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:10:04.137+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:10:14.614+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:10:14.324+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/newspipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/newspipeline.py", line 106, in <module>
    load_data_to_postgres(df, table_name, conn_string)
  File "/opt/airflow/dags/newspipeline.py", line 62, in load_data_to_postgres
    conn = psycopg2.connect(conn_string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution
[2024-07-10T10:10:14.818+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:10:24.898+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 843, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 622, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-07-10T10:10:56.636+0000] {processor.py:161} INFO - Started process (PID=652) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:10:56.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:10:56.638+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:10:56.637+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:11:28.373+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:11:26.985+0000] {timeout.py:68} ERROR - Process timed out, PID: 652
[2024-07-10T10:12:05.946+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:12:05.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:12:05.947+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:12:05.947+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:12:36.106+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:12:35.962+0000] {timeout.py:68} ERROR - Process timed out, PID: 664
[2024-07-10T10:13:10.680+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:13:10.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:13:10.683+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:13:10.681+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:13:42.418+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:13:41.199+0000] {timeout.py:68} ERROR - Process timed out, PID: 678
[2024-07-10T10:15:44.691+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:15:44.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:15:44.694+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:15:44.693+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:16:03.488+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:16:03.993+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:16:04.005+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:16:04.161+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:16:04.161+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:16:04.180+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:16:04.180+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:16:04.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 19.521 seconds
[2024-07-10T10:16:34.359+0000] {processor.py:161} INFO - Started process (PID=700) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:16:34.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:16:34.361+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:16:34.360+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:16:55.014+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:16:55.613+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:16:55.618+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:16:55.641+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:16:55.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:16:55.659+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:16:55.659+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:16:55.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 21.323 seconds
[2024-07-10T10:17:26.415+0000] {processor.py:161} INFO - Started process (PID=714) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:17:26.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:17:26.417+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:17:26.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:17:56.431+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:17:56.427+0000] {timeout.py:68} ERROR - Process timed out, PID: 714
[2024-07-10T10:18:26.631+0000] {processor.py:161} INFO - Started process (PID=728) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:18:26.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:18:26.634+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:18:26.633+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:18:45.083+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:18:45.545+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:18:45.554+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:18:45.689+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:18:45.689+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:18:45.711+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:18:45.711+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:18:45.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 19.107 seconds
[2024-07-10T10:19:15.933+0000] {processor.py:161} INFO - Started process (PID=742) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:19:15.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:19:15.935+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:19:15.935+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:19:46.002+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:19:45.971+0000] {timeout.py:68} ERROR - Process timed out, PID: 742
[2024-07-10T10:20:17.062+0000] {processor.py:161} INFO - Started process (PID=750) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:20:17.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:20:17.063+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:20:17.063+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:20:50.367+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:20:47.114+0000] {timeout.py:68} ERROR - Process timed out, PID: 750
[2024-07-10T10:23:31.277+0000] {processor.py:161} INFO - Started process (PID=764) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:23:31.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:23:31.279+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:23:31.279+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:23:51.039+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:23:51.696+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:23:51.712+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:23:51.944+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:23:51.943+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:23:51.974+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:23:51.974+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:23:51.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 18.358 seconds
[2024-07-10T10:24:22.727+0000] {processor.py:161} INFO - Started process (PID=778) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:24:22.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:24:22.728+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:24:22.728+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:24:41.612+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:24:42.073+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:24:42.078+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:24:42.186+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:24:42.186+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:24:42.202+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:24:42.202+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:24:42.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 19.897 seconds
[2024-07-10T10:25:12.334+0000] {processor.py:161} INFO - Started process (PID=793) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:25:12.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:25:12.336+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:25:12.335+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:25:43.141+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:25:42.564+0000] {timeout.py:68} ERROR - Process timed out, PID: 793
[2024-07-10T10:26:14.682+0000] {processor.py:161} INFO - Started process (PID=801) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:26:14.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:26:14.684+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:26:14.684+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:26:35.596+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:26:36.045+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:26:36.056+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:26:36.187+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:26:36.186+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:26:36.203+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:26:36.203+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:26:36.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 21.544 seconds
[2024-07-10T10:27:06.432+0000] {processor.py:161} INFO - Started process (PID=814) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:27:06.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:27:06.434+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:27:06.434+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:27:39.344+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:27:39.343+0000] {timeout.py:68} ERROR - Process timed out, PID: 814
[2024-07-10T10:28:22.347+0000] {processor.py:161} INFO - Started process (PID=835) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:28:22.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:28:22.350+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:28:22.349+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:28:56.770+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:28:52.829+0000] {timeout.py:68} ERROR - Process timed out, PID: 835
[2024-07-10T10:29:43.333+0000] {processor.py:161} INFO - Started process (PID=843) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:29:43.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:29:43.337+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:29:43.335+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:30:13.781+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:30:13.605+0000] {timeout.py:68} ERROR - Process timed out, PID: 843
[2024-07-10T10:30:45.295+0000] {processor.py:161} INFO - Started process (PID=858) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:30:45.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:30:45.300+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:30:45.298+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:31:23.801+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:31:15.557+0000] {timeout.py:68} ERROR - Process timed out, PID: 858
[2024-07-10T10:32:18.539+0000] {processor.py:161} INFO - Started process (PID=860) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:32:18.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:32:18.541+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:32:18.540+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:32:48.637+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:32:48.636+0000] {timeout.py:68} ERROR - Process timed out, PID: 860
[2024-07-10T10:33:18.800+0000] {processor.py:161} INFO - Started process (PID=874) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:33:18.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:33:18.802+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:33:18.802+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:33:40.437+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:33:41.020+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:33:41.035+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:33:41.192+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:33:41.191+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:33:41.209+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:33:41.208+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:33:41.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 22.417 seconds
[2024-07-10T10:34:11.373+0000] {processor.py:161} INFO - Started process (PID=887) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:34:11.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:34:11.387+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:34:11.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:34:42.552+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:34:41.789+0000] {timeout.py:68} ERROR - Process timed out, PID: 887
[2024-07-10T10:35:39.267+0000] {processor.py:161} INFO - Started process (PID=895) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:35:39.268+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:35:39.269+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:35:39.269+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:36:00.525+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:36:01.769+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:36:01.787+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:36:01.940+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:36:01.939+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:36:01.959+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:36:01.958+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:36:01.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 22.695 seconds
[2024-07-10T10:36:32.167+0000] {processor.py:161} INFO - Started process (PID=903) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:36:32.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:36:32.170+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:36:32.168+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:37:02.460+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:37:02.213+0000] {timeout.py:68} ERROR - Process timed out, PID: 903
[2024-07-10T10:37:38.281+0000] {processor.py:161} INFO - Started process (PID=916) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:37:38.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:37:38.286+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:37:38.284+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:37:57.529+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:37:58.165+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:37:58.177+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:37:58.313+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:37:58.313+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:37:58.329+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:37:58.329+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:37:58.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 20.945 seconds
[2024-07-10T10:38:28.517+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:38:28.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:38:28.519+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:38:28.519+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:38:58.528+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:38:58.528+0000] {timeout.py:68} ERROR - Process timed out, PID: 930
[2024-07-10T10:39:28.781+0000] {processor.py:161} INFO - Started process (PID=944) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:39:28.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:39:28.783+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:39:28.782+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:39:43.758+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T10:39:44.307+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T10:39:44.320+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:39:44.485+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:39:44.485+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T10:39:44.507+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:39:44.507+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T10:39:44.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 15.749 seconds
[2024-07-10T10:40:14.700+0000] {processor.py:161} INFO - Started process (PID=958) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:40:14.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:40:14.702+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:40:14.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:40:45.439+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:40:44.845+0000] {timeout.py:68} ERROR - Process timed out, PID: 958
[2024-07-10T10:41:45.518+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:41:45.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:41:45.520+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:41:45.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:42:15.093+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:42:15.092+0000] {timeout.py:68} ERROR - Process timed out, PID: 965
[2024-07-10T10:42:45.298+0000] {processor.py:161} INFO - Started process (PID=978) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:42:45.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:42:45.300+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:42:45.300+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:43:15.309+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:43:15.308+0000] {timeout.py:68} ERROR - Process timed out, PID: 978
[2024-07-10T10:43:45.476+0000] {processor.py:161} INFO - Started process (PID=992) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:43:45.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:43:45.478+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:43:45.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:44:15.625+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:44:15.592+0000] {timeout.py:68} ERROR - Process timed out, PID: 992
[2024-07-10T10:44:47.136+0000] {processor.py:161} INFO - Started process (PID=1006) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:44:47.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:44:47.138+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:44:47.138+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:45:20.245+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:45:17.301+0000] {timeout.py:68} ERROR - Process timed out, PID: 1006
[2024-07-10T10:46:20.204+0000] {processor.py:161} INFO - Started process (PID=1013) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:46:20.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:46:20.206+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:46:20.206+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:46:50.188+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:46:50.188+0000] {timeout.py:68} ERROR - Process timed out, PID: 1013
[2024-07-10T10:47:20.364+0000] {processor.py:161} INFO - Started process (PID=1028) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:47:20.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:47:20.366+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:47:20.366+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:47:50.372+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:47:50.372+0000] {timeout.py:68} ERROR - Process timed out, PID: 1028
[2024-07-10T10:48:20.575+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:48:20.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:48:20.576+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:48:20.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:48:51.330+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:48:50.638+0000] {timeout.py:68} ERROR - Process timed out, PID: 1042
[2024-07-10T10:49:26.124+0000] {processor.py:161} INFO - Started process (PID=1055) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T10:49:26.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T10:49:26.126+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:49:26.125+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T10:49:58.665+0000] {logging_mixin.py:188} INFO - [2024-07-10T10:49:56.809+0000] {timeout.py:68} ERROR - Process timed out, PID: 1055
[2024-07-10T11:13:29.287+0000] {processor.py:161} INFO - Started process (PID=27) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:13:29.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:13:29.302+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:13:29.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:14:08.178+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:14:08.178+0000] {timeout.py:68} ERROR - Process timed out, PID: 27
[2024-07-10T11:14:39.532+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:14:39.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:14:39.541+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:14:39.537+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:15:09.574+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:15:09.570+0000] {timeout.py:68} ERROR - Process timed out, PID: 41
[2024-07-10T11:15:40.642+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:15:40.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:15:40.673+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:15:40.673+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:16:10.792+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:16:10.703+0000] {timeout.py:68} ERROR - Process timed out, PID: 55
[2024-07-10T11:16:41.924+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:16:41.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:16:41.927+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:16:41.927+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:17:32.582+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:17:13.571+0000] {timeout.py:68} ERROR - Process timed out, PID: 63
[2024-07-10T11:18:06.496+0000] {processor.py:161} INFO - Started process (PID=65) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:18:06.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:18:06.526+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:18:06.522+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:18:37.458+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:18:36.813+0000] {timeout.py:68} ERROR - Process timed out, PID: 65
[2024-07-10T11:19:10.711+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:19:10.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:19:10.714+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:19:10.713+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:19:46.208+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:19:46.171+0000] {timeout.py:68} ERROR - Process timed out, PID: 79
[2024-07-10T11:20:17.160+0000] {processor.py:161} INFO - Started process (PID=86) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:20:17.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:20:17.167+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:20:17.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:20:47.210+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:20:47.188+0000] {timeout.py:68} ERROR - Process timed out, PID: 86
[2024-07-10T11:21:19.244+0000] {processor.py:161} INFO - Started process (PID=99) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:21:19.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:21:19.247+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:21:19.246+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:21:49.472+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:21:49.450+0000] {timeout.py:68} ERROR - Process timed out, PID: 99
[2024-07-10T11:22:19.890+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:22:19.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:22:19.896+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:22:19.894+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:22:49.944+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:22:49.943+0000] {timeout.py:68} ERROR - Process timed out, PID: 113
[2024-07-10T11:23:20.201+0000] {processor.py:161} INFO - Started process (PID=128) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:23:20.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:23:20.204+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:23:20.203+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:23:50.232+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:23:50.231+0000] {timeout.py:68} ERROR - Process timed out, PID: 128
[2024-07-10T11:24:20.390+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:24:20.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:24:20.393+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:24:20.392+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:24:50.901+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:24:50.416+0000] {timeout.py:68} ERROR - Process timed out, PID: 142
[2024-07-10T11:25:23.111+0000] {processor.py:161} INFO - Started process (PID=155) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:25:23.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:25:23.118+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:25:23.114+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:25:55.659+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:25:55.356+0000] {timeout.py:68} ERROR - Process timed out, PID: 155
[2024-07-10T11:27:10.770+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:27:10.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:27:10.778+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:27:10.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:27:40.831+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:27:40.793+0000] {timeout.py:68} ERROR - Process timed out, PID: 168
[2024-07-10T11:28:11.479+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:28:11.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:28:11.483+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:28:11.482+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:28:41.968+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:28:41.503+0000] {timeout.py:68} ERROR - Process timed out, PID: 182
[2024-07-10T11:29:14.467+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:29:14.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:29:14.470+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:29:14.470+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:29:45.579+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:29:44.590+0000] {timeout.py:68} ERROR - Process timed out, PID: 190
[2024-07-10T11:30:21.010+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:30:21.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:30:21.013+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:30:21.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:30:51.604+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:30:51.144+0000] {timeout.py:68} ERROR - Process timed out, PID: 203
[2024-07-10T11:31:31.963+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:31:31.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:31:31.968+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:31:31.965+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:32:04.279+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:32:02.257+0000] {timeout.py:68} ERROR - Process timed out, PID: 217
[2024-07-10T11:32:56.640+0000] {processor.py:161} INFO - Started process (PID=231) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:32:56.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:32:56.644+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:32:56.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:33:26.941+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:33:26.619+0000] {timeout.py:68} ERROR - Process timed out, PID: 231
[2024-07-10T11:33:59.184+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:33:59.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:33:59.187+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:33:59.187+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:34:29.217+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:34:29.197+0000] {timeout.py:68} ERROR - Process timed out, PID: 245
[2024-07-10T11:34:59.525+0000] {processor.py:161} INFO - Started process (PID=253) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:34:59.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:34:59.531+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:34:59.528+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:35:30.675+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:35:29.777+0000] {timeout.py:68} ERROR - Process timed out, PID: 253
[2024-07-10T11:36:35.212+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:36:35.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:36:35.215+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:36:35.215+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:37:05.269+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:37:05.268+0000] {timeout.py:68} ERROR - Process timed out, PID: 267
[2024-07-10T11:37:35.472+0000] {processor.py:161} INFO - Started process (PID=281) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:37:35.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:37:35.479+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:37:35.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:38:05.487+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:38:05.486+0000] {timeout.py:68} ERROR - Process timed out, PID: 281
[2024-07-10T11:38:36.761+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:38:36.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:38:36.765+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:38:36.765+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:39:06.779+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:39:06.776+0000] {timeout.py:68} ERROR - Process timed out, PID: 301
[2024-07-10T11:39:36.971+0000] {processor.py:161} INFO - Started process (PID=315) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:39:36.972+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:39:36.973+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:39:36.973+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:40:06.990+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:40:06.986+0000] {timeout.py:68} ERROR - Process timed out, PID: 315
[2024-07-10T11:40:37.170+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:40:37.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:40:37.173+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:40:37.172+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:41:07.261+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:41:07.196+0000] {timeout.py:68} ERROR - Process timed out, PID: 329
[2024-07-10T11:41:40.550+0000] {processor.py:161} INFO - Started process (PID=337) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:41:40.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:41:40.553+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:41:40.552+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:42:11.534+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:42:10.867+0000] {timeout.py:68} ERROR - Process timed out, PID: 337
[2024-07-10T11:42:41.567+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:42:41.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:42:41.576+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:42:41.571+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:43:12.002+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:43:11.629+0000] {timeout.py:68} ERROR - Process timed out, PID: 351
[2024-07-10T11:44:16.641+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T11:44:16.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T11:44:16.648+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:44:16.644+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T11:44:53.016+0000] {logging_mixin.py:188} INFO - [2024-07-10T11:44:47.114+0000] {timeout.py:68} ERROR - Process timed out, PID: 363
[2024-07-10T12:03:28.465+0000] {processor.py:161} INFO - Started process (PID=26) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:03:28.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:03:28.474+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:03:28.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:03:58.800+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:03:58.543+0000] {timeout.py:68} ERROR - Process timed out, PID: 26
[2024-07-10T12:04:29.380+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:04:29.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:04:29.385+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:04:29.383+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:04:59.401+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:04:59.400+0000] {timeout.py:68} ERROR - Process timed out, PID: 40
[2024-07-10T12:05:29.608+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:05:29.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:05:29.611+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:05:29.611+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:05:53.733+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T12:05:54.215+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T12:05:54.231+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:05:54.390+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:05:54.390+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T12:05:54.410+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:05:54.410+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T12:05:54.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 24.832 seconds
[2024-07-10T12:06:24.601+0000] {processor.py:161} INFO - Started process (PID=67) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:06:24.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:06:24.604+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:06:24.603+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:06:48.921+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T12:06:49.402+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T12:06:49.418+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:06:49.460+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:06:49.460+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T12:06:49.486+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:06:49.486+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T12:06:49.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 24.908 seconds
[2024-07-10T12:07:19.649+0000] {processor.py:161} INFO - Started process (PID=80) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:07:19.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:07:19.652+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:07:19.652+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:07:49.653+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:07:49.650+0000] {timeout.py:68} ERROR - Process timed out, PID: 80
[2024-07-10T12:08:19.816+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:08:19.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:08:19.818+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:08:19.818+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:08:50.473+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:08:49.941+0000] {timeout.py:68} ERROR - Process timed out, PID: 94
[2024-07-10T12:09:21.127+0000] {processor.py:161} INFO - Started process (PID=102) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:09:21.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:09:21.130+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:09:21.128+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:09:51.188+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:09:51.144+0000] {timeout.py:68} ERROR - Process timed out, PID: 102
[2024-07-10T12:10:26.844+0000] {processor.py:161} INFO - Started process (PID=117) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:10:26.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:10:26.846+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:10:26.846+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:10:58.199+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:10:57.208+0000] {timeout.py:68} ERROR - Process timed out, PID: 117
[2024-07-10T12:11:33.175+0000] {processor.py:161} INFO - Started process (PID=129) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:11:33.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:11:33.177+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:11:33.177+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:12:06.673+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:12:05.259+0000] {timeout.py:68} ERROR - Process timed out, PID: 129
[2024-07-10T12:12:48.670+0000] {processor.py:161} INFO - Started process (PID=143) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:12:48.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:12:48.672+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:12:48.671+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:13:34.843+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:13:22.050+0000] {timeout.py:68} ERROR - Process timed out, PID: 143
[2024-07-10T12:20:43.496+0000] {processor.py:161} INFO - Started process (PID=156) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:20:43.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:20:43.498+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:20:43.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:21:23.556+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:21:15.087+0000] {timeout.py:68} ERROR - Process timed out, PID: 156
[2024-07-10T12:22:15.451+0000] {processor.py:161} INFO - Started process (PID=169) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:22:15.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:22:15.455+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:22:15.452+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:22:45.471+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:22:45.466+0000] {timeout.py:68} ERROR - Process timed out, PID: 169
[2024-07-10T12:23:15.746+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:23:15.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:23:15.752+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:23:15.751+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:23:47.863+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:23:47.775+0000] {timeout.py:68} ERROR - Process timed out, PID: 184
[2024-07-10T12:31:53.875+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:31:53.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:31:53.983+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:31:53.982+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:32:27.002+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:32:27.001+0000] {timeout.py:68} ERROR - Process timed out, PID: 43
[2024-07-10T12:33:04.760+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:33:04.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:33:04.954+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:33:04.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:33:36.134+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:33:36.014+0000] {timeout.py:68} ERROR - Process timed out, PID: 50
[2024-07-10T12:34:06.936+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:34:06.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:34:06.947+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:34:06.945+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:34:36.987+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:34:36.969+0000] {timeout.py:68} ERROR - Process timed out, PID: 69
[2024-07-10T12:35:07.242+0000] {processor.py:161} INFO - Started process (PID=84) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:35:07.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:35:07.284+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:35:07.284+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:35:37.324+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:35:37.322+0000] {timeout.py:68} ERROR - Process timed out, PID: 84
[2024-07-10T12:36:07.566+0000] {processor.py:161} INFO - Started process (PID=98) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:36:07.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:36:07.587+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:36:07.586+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:36:37.623+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:36:37.609+0000] {timeout.py:68} ERROR - Process timed out, PID: 98
[2024-07-10T12:37:08.294+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:37:08.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:37:08.299+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:37:08.299+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:37:39.593+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:37:38.760+0000] {timeout.py:68} ERROR - Process timed out, PID: 105
[2024-07-10T12:38:13.046+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:38:13.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:38:13.066+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:38:13.066+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:38:43.456+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:38:43.261+0000] {timeout.py:68} ERROR - Process timed out, PID: 119
[2024-07-10T12:39:14.471+0000] {processor.py:161} INFO - Started process (PID=133) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:39:14.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:39:14.474+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:39:14.473+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:39:44.873+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:39:44.631+0000] {timeout.py:68} ERROR - Process timed out, PID: 133
[2024-07-10T12:40:17.827+0000] {processor.py:161} INFO - Started process (PID=145) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:40:17.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:40:17.830+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:40:17.829+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:40:48.991+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:40:48.001+0000] {timeout.py:68} ERROR - Process timed out, PID: 145
[2024-07-10T12:41:24.142+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:41:24.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:41:24.144+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:41:24.144+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:42:00.608+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:41:55.540+0000] {timeout.py:68} ERROR - Process timed out, PID: 160
[2024-07-10T12:42:46.408+0000] {processor.py:161} INFO - Started process (PID=173) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:42:46.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:42:46.411+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:42:46.411+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:43:32.206+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:43:17.984+0000] {timeout.py:68} ERROR - Process timed out, PID: 173
[2024-07-10T12:44:08.255+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:44:08.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:44:08.258+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:44:08.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:44:24.191+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T12:44:25.112+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T12:44:25.128+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:44:25.642+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:44:25.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T12:44:25.802+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:44:25.801+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T12:44:25.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 17.606 seconds
[2024-07-10T12:44:56.013+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:44:56.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:44:56.016+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:44:56.016+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:45:27.359+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:45:26.542+0000] {timeout.py:68} ERROR - Process timed out, PID: 195
[2024-07-10T12:50:50.685+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:50:50.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:50:50.689+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:50:50.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:51:21.291+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:51:20.688+0000] {timeout.py:68} ERROR - Process timed out, PID: 208
[2024-07-10T12:53:10.314+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:53:10.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:53:10.315+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:53:10.315+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:53:46.909+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:53:45.914+0000] {timeout.py:68} ERROR - Process timed out, PID: 222
[2024-07-10T12:55:24.858+0000] {processor.py:161} INFO - Started process (PID=231) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:55:24.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:55:24.859+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:55:24.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:55:54.763+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:55:54.762+0000] {timeout.py:68} ERROR - Process timed out, PID: 231
[2024-07-10T12:56:24.898+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:56:24.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:56:24.900+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:56:24.900+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:56:52.262+0000] {logging_mixin.py:188} INFO - Successfully saved 1000 articles to ai_news_articles.json and ai_news_articles.csv
[2024-07-10T12:56:52.874+0000] {logging_mixin.py:188} INFO - Successfully loaded data into news_articles table
[2024-07-10T12:56:52.891+0000] {processor.py:840} INFO - DAG(s) 'etl_data_pipeline' retrieved from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:56:53.113+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:56:53.113+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-07-10T12:56:53.139+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:56:53.139+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_data_pipeline to 2024-07-09 00:00:00+00:00, run_after=2024-07-10 00:00:00+00:00
[2024-07-10T12:56:53.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/newspipeline.py took 28.264 seconds
[2024-07-10T12:57:23.293+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:57:23.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:57:23.295+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:57:23.294+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:57:54.951+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:57:53.984+0000] {timeout.py:68} ERROR - Process timed out, PID: 259
[2024-07-10T12:58:33.117+0000] {processor.py:161} INFO - Started process (PID=273) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:58:33.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:58:33.131+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:58:33.131+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T12:59:03.592+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:59:03.553+0000] {timeout.py:68} ERROR - Process timed out, PID: 273
[2024-07-10T12:59:37.928+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T12:59:37.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T12:59:37.938+0000] {logging_mixin.py:188} INFO - [2024-07-10T12:59:37.929+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T13:00:08.586+0000] {logging_mixin.py:188} INFO - [2024-07-10T13:00:08.572+0000] {timeout.py:68} ERROR - Process timed out, PID: 287
[2024-07-10T13:00:40.894+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/newspipeline.py
[2024-07-10T13:00:40.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/newspipeline.py for tasks to queue
[2024-07-10T13:00:40.929+0000] {logging_mixin.py:188} INFO - [2024-07-10T13:00:40.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/newspipeline.py
[2024-07-10T13:01:27.726+0000] {logging_mixin.py:188} INFO - [2024-07-10T13:01:16.968+0000] {timeout.py:68} ERROR - Process timed out, PID: 296
